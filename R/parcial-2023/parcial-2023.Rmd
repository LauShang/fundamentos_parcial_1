---
title: "Parcial-2023"
author: "Lauro Reyes Rosas 000213245"
        "Sara luz Valenzuela Camacho 000204535"
date: "2023-10-04"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

**Entrega:** 10 de octubre antes de las 16:00 horas, por correo electrónico con el título fundamentos-parcial, un solo documento (pdf/html) por equipo.

**Instrucciones:**

-   Tus respuestas deben ser claras y debes explicar los resultados, incluye también tus procedimientos/código de manera ordenada, y el código comentado.

-   Se evaluará la presentación de resultados (calidad de las gráficas, tablas, ...), revisa la sección de visualización en las notas.

-   Se puede realizar individual o en parejas.

-   Si tienes preguntas puedes escribirlas en el anuncio de canvas del examen.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, error = TRUE, message = FALSE)
library(tidyverse)
library(nullabor)
library(janitor)
library(dplyr)
library(ggplot2)
library(patchwork)
library(purrr)
```

## Pruebas de hipótesis

Nos solicitan hacer un análisis con el objetivo de probar un material nuevo para suela de zapatos (el material B) y ver si es comparable con el material que se usa normalmente (el material A).

Nos dan el siguiente conjunto de datos:

```{r}
zapatos <- read_csv("datos/zapatos-1.csv")
zapatos <- zapatos %>% mutate(material = paste('material',as.character(material) ) )
zapatos
```

1.  Realiza una prueba de hipótesis visual y describe tus conclusiones (cuál es el nivel de significancia de la prueba?).

    ```{r}
#Use el ejercicio 04 (visto en clase) para resolver éste
set.seed(12345)
perms_material <- lineup(null_permute("material"), zapatos, n = 10)
ggplot(perms_material, aes(x = material, y = desgaste)) +
  geom_boxplot() + facet_wrap(~.sample) 
    ```

```{r}
decrypt("mNfY ky7y wq Fxrw7wxq uW")
```
**No tenemos evidencia de que haya diferencia entre los materiales, ya que no pudimos distinguir en la prueba visual los datos reales. De haberlo distinguido el nivel de significancia sería de 1/10 **


2.  Realiza una prueba de permutaciones para la diferencia de las medias, escribe la hipótesis nula, la hipótesis alterna y tus conclusiones.

**Primero vamos a calcular la diferencia observada en el promedio del desgaste para ambos materiales**

```{r}
#Use la tarea 04 para resolver éste

promedios <- zapatos |> 
  group_by(material) |> 
  summarize(prom_desgaste = mean(desgaste, na.rm = TRUE)) |> 
  pivot_wider(names_from = material, values_from = prom_desgaste) |>
  rename("m1" = "material 1", "m2" = "material 2") |> 
  mutate(diferencia1 = m2 - m1)

diferencia_observada <- promedios |>   pull (diferencia1) |> round(3)

diferencia_observada

```
**La hipotesis nula es que los dos materiales tienen distribuciones iguales, esto es mismo desgaste**

**Bajo nuestra hipotesis nula, producimos una cantidad grande de muestras permutando las etiquetas de los grupos.**

```{r}
#Hacemos las permutaciones del material
permut_material <- lineup(null_permute("material"), zapatos, n=5000)
glimpse(permut_material)
```

Evaluamos nuestra estadistica de prueba en cada una de las muestras permutadas

```{r}
valores_ref <- permut_material |> 
  group_by(material, .sample) |> 
  summarise(media = mean(desgaste)) |> 
  pivot_wider(names_from = material, values_from = media) |> 
  rename("m1" = "material 1", "m2" = "material 2") |>
  mutate(diferencia = m2 - m1)

valores_ref
```



```{r}
dist_perm <- ecdf(valores_ref$diferencia)

percentil_obs <- dist_perm(diferencia_observada)

g_1 <- ggplot(valores_ref, aes(sample = diferencia)) + geom_qq(distribution = stats::qunif)  +
  xlab("f") + ylab("diferencia") + labs(subtitle = "Distribución nula o de referencia") +
  geom_hline(yintercept = diferencia_observada, colour = "red") +
  annotate("text", x = 0.35, y = diferencia_observada - 0.1, label = "diferencia observada", colour = "red")

g_2 <- ggplot(valores_ref, aes(x = diferencia)) + geom_histogram(binwidth = 0.04) +
  coord_flip() + xlab("") + labs(subtitle = " ") +
  geom_vline(xintercept = diferencia_observada, colour = "red") +
  annotate("text", x = diferencia_observada, y = 1500 * .3, label = percentil_obs,vjust = -0.2, colour = "red")
g_1 + g_2
```




```{r}
2*min(dist_perm(diferencia_observada),(1-dist_perm(diferencia_observada)))
```

**Tiene un 68% de probabilidad de ocurrir, por lo que no hay mucha evidencia encontra de la hipotesis nula.**



3.  Después de discutir con los responsables del proyecto descubrimos que nos faltaba conocer detalles del proceso generador de datos: el experimento se realizó asignando al azar un material a uno de sus zapatos y el otro material al otro zapato de cada niño. ¿Cómo incorporas esta información en tu prueba de hipótesis del inciso 2? ¿Cambian tus conclusiones?

**Ésta es un prueba pareada, ya que se puede decir que ambos pies de cada niño son similares, por lo que debemos de tener cuidado de no destruir esta estructura. Para ello lo que debemos hacer es permutar al azar en cada niño el desgaste de cada zapato. Esto al azar vamos a decidir si para el i-ésimo niño cambiamos el desgaste del material 1 y 2, o si los dejamos como están.**

```{r}
zapatos <- read_csv("datos/zapatos-2.csv")
zapatos <- zapatos %>% 
  pivot_wider(names_from = material, values_from = desgaste) %>% 
  rename("id" = "niño", "m1" = "1", "m2" = "2") %>% 
  mutate(diff = m1 - m2 )
  
zapatos
```

**Nuestra hipotesís nula es que ambos materiales se desgastan igual, que implica que al restar el desgaste por niño del material A y luego del material B, y luego sacar el promedio de todos los niños de ésta diferencia, vamos a obtener cero**

```{r}
#https://www.youtube.com/watch?v=3e6ZM-oWwbM

m = 5000

nulldist <- rep(12345, m) 
dif_prom <- zapatos %>% 
  summarise(prom = mean(diff)) %>% 
  pull(prom)

n <- nrow(zapatos)

set.seed(1234)

dif_prom

```
Seleccionamos al azar algunos niños a los que se les va a cambiar el signo de su diferencia en desgaste

```{r}
for(i in 1:m){
  signs <- sample(c(-1,1), size = n, replace = TRUE)
  simdiffs <- signs*zapatos$diff
  nulldist[i] <- mean(simdiffs)
}
```



```{r}
hist(nulldist)
abline(v = dif_prom, col = "red") 

```

**Como nuestra hipótesis nula señala que nodebe hacer difrencia entre ambos materiales, vemos que el histograma es congruente ya que tiene su media en cero**


```{r}
# nuestra diferencia calculada con la muestra original
(lowtail <- sum(nulldist <= dif_prom)+1) 
# el número de veces que la diferencia fue mayor al calculado (más uno porque tomamos en cuenta el calculado con la original)
(uptail <- sum(nulldist >= dif_prom)+1)
# el número de veces que la diferencia fue menor al calculado (más uno porque tomamos en cuenta el calculado con la original)
(numerator <- min(lowtail, uptail))
# tomamos el menor de estos dos números
denom <- m+1
(pval <- 2*numerator/denom)
```

**Como nuestra hipótesis alterna es que sí existe una diferencia, ya sea negativa o positiva, tenemos que usar dos colas.**

```{r}
(pval <- 2*numerator/denom)
```
**Tiene un 1% de probabilidad de ocurrir, por lo que sí hay evidencia encontra de la hipotesis nula. Que significa que sí hay diferencia en el desgaste entre los materiales A y B**

## Bootstrap

#### Antecedentes

En México, las elecciones tienen lugar un domingo, los resultados oficiales del proceso se presentan a la población una semana después. A fin de evitar proclamaciones de victoria injustificadas durante ese periodo el INE organiza un conteo rápido. Un conteo rápido es un procedimiento para estimar, a partir de una muestra aleatoria de casillas, el porcentaje de votos a favor de cada opción en la boleta.

En 2021 se realizó un conteo rápido para estimar los resultados de la [consulta popular 2021](https://ine.mx/conteo-rapido-consulta-popular-2021/) y en los siguientes incisos estimarán los resultados de la consulta y evaluarán la metodología.

##### Diseño de la muestra

El diseño utilizado en los conteos rápidos es *muestreo estratificado simple*, es decir:

i)  se particionan las casillas de la pablación en estratos (cada casilla pertenece a exactamente un estrato), y

ii) dentro de cada estrato se usa *muestreo aleatorio* para seleccionar las casillas que estarán en la muestra.

##### Estimación

Una de las metodolgías de estimación, que se usa en el conteo rápido (tanto de elecciones como en consultas) es *estimador de razón combinado*, con intervalos de 95% de confianza construidos con el método normal y error estándar bootstrap. En este ejercicio debes construir intervalos usando este procedimiento.

Para cada opción en la consulta (sí/no/nulos) usarás la muestra del conteo rápido para estimar los resultados de la consulta.

1.  Calcula el estimador de razón combinado, para muestreo estratificado la fórmula es:

$$\hat{p}=\frac{\sum_h \frac{N_h}{n_h} \sum_i Y_{hi}}{\sum_h \frac{N_h}{n_h} \sum_i X_{hi}}$$ donde:

-   $\hat{p}$ es la estimación de la proporción de votos que recibió la opción (ej: *sí*).

-   $Y_{hi}$ es el número total de votos que recibió *la opción* (ej: *sí*) en la $i$-ésima casillas, que pertence al $h$-ésimo estrato.

-   $X_{hi}$ es el número total de votos en la $i$-ésima casilla, que pertence al $h$-ésimo estrato.

-   $N_h$ es el número total de casillas en el $h$-ésimo estrato.

-   $n_h$ es el número de casillas del $h$-ésimo estrato que se seleccionaron en la muestra.

##### Datos

Necesitarás los siguientes datos:

-   Cómputos [aquí](https://computos.cp2021.ine.mx/votos-distrito/mapa)

-   Muestra del conteo rápido usada en la estimación [aquí](https://ine.mx/conteo-rapido-consulta-popular-2021/)

```{r}
# preprocesamiento de tablas de datos
computos <- read_delim("datos/20210802-2130_INE-CONSULTA-POPULAR-2021/20210802-2130_COMPUTOS-INE-CP2021.csv", 
    delim = "|", escape_double = FALSE, trim_ws = TRUE, quote = "\'",
    skip = 5)
computos <- computos |> 
  rename(ID = CLAVE_MRCP) |> 
  mutate(ESTRATO = str_c(str_pad(ID_ENTIDAD, 2, pad = "0"), 
                         str_pad(ID_DISTRITO_FEDERAL, 2, pad = "0")),
         LISTA_NOMINAL = LISTA_NOMINAL_MRCP, 
         TOTAL = TOTAL_OPINIONES)

muestra <- read_delim("https://ine.mx/wp-content/uploads/2021/08/Conteos-ConsPop21-Lista-MuestraCalculo.txt", delim = "|", skip = 1) 
muestra_tidy <- muestra |> 
  mutate(
    ID_ESTADO = str_pad(ID_ESTADO, 2, pad = "0"),
    SECCION = str_pad(SECCION, 4, pad = "0"),
    ID_CASILLA = str_pad(ID_CASILLA, 2, pad = "0"),
    ID = str_c(ID_ESTADO, SECCION, TIPO_CASILLA, ID_CASILLA)
    ) |> 
  group_by(ESTRATO) |> 
  mutate(n = n()) |> 
  ungroup()
```


```{r}
glimpse(muestra_tidy) #SI, NO, NULOS, ESTRATO, ID
glimpse(computos) #OPINION_SI, OPINION_NO, NULOS, ESTRATO, ID
muestra %>% summarise_all(list(~n_distinct(.)))
computos %>% summarise_all(list(~n_distinct(.)))
nm <- nrow(muestra_tidy)
nc <- nrow(computos)
```

```{r}
#https://ayuda.ine.mx/2021/informate/assets/consultapopular/manual-interpretacion-bd.pdf
#muestra <- muestra %>% 
#  mutate(ID_est = as.character(sprintf("%02d", ID_ESTADO ) ) ) %>% 
#  mutate(SEDE = as.character(sprintf("%04d", SECCION ) ) ) %>%
#  mutate(IDCAS = as.character(sprintf("%02d", ID_CASILLA ) ) ) %>%
#  mutate(ID = paste0(ID_est,SEDE,TIPO_CASILLA,IDCAS))
#glimpse(muestra)

tabla1 <- computos %>%
  select(ID, ESTRATO)

tabla2 <- muestra_tidy %>% #casillas en el i-ésimo estrato de la muestra
  group_by(ID, ESTRATO, SI, NO, NULOS, TOTAL) %>% 
  summarise(mues_casXest = n())

tabla3 <- merge(x=tabla1,y=tabla2, 
             by=c("ID"="ID","ESTRATO"="ESTRATO"), all.x = TRUE)

colSums(is.na(tabla3))

tabla4 <- merge(x=tabla1,y=tabla2, 
             by=c("ID"="ID","ESTRATO"="ESTRATO"), all.y = TRUE)

colSums(is.na(tabla4))

tabla3 <-  tabla3 %>% 
  mutate(tabla3, mues_casXest = ifelse(is.na(mues_casXest), 0, mues_casXest)) 


colSums(is.na(tabla3))

tabla3 <- tabla3 %>% filter(is.na(ESTRATO)) 
tabla3 <- tabla3 %>% mutate(tabla3, ESTRATO = ifelse(is.na(ESTRATO), 0, ESTRATO)) 
tabla3 <- tabla3 %>% mutate(tabla3, SI = ifelse(is.na(SI), 0, SI)) 
tabla3 <- tabla3 %>% mutate(tabla3, NO = ifelse(is.na(NO), 0, NO)) 
tabla3 <- tabla3 %>% mutate(tabla3, NULOS = ifelse(is.na(NULOS), 0, NULOS)) 
tabla3 <- tabla3 %>% mutate(tabla3, TOTAL = ifelse(is.na(TOTAL), 0, TOTAL))

tabla3 <- rbind(tabla3, tabla4)

#tabla1
#tabla2
tabla3
#tabla4
```

```{r}

tabla5 <- tabla3 %>% 
  group_by(ESTRATO) %>% 
  summarise(Nh = n(), 
            nh = sum(mues_casXest), 
            yh_SI = sum(SI), 
            yh_NO = sum(NO), 
            yh_NUL = sum(NULOS),
            xh = sum(TOTAL)) %>% 
  mutate(p_SI_num =  Nh/nh*yh_SI,
         p_NO_num =  Nh/nh*yh_NO,
         p_NUL_num = Nh/nh*yh_NUL,
         p_denominador = Nh/nh*xh)

tabla5

```




```{r}
tabla6 <- tabla5 %>% 
  summarise(p_SI = sum(p_SI_num)/sum(p_denominador),
            p_NO = sum(p_NO_num)/sum(p_denominador),
            p_NUL = sum(p_NUL_num)/sum(p_denominador))

tabla6

```



```{r}
#Comprobación
propSi = tabla6[1]
propNo = tabla6[2]
propNu = tabla6[3]
propSi + propNo + propNu

```



2.  Utiliza **bootstrap** para calcular el error estándar, y reporta tu estimación del error.

    -   Genera 1000 muestras bootstrap.
    -   Recuerda que las muestras bootstrap tienen que tomar en cuenta la metodología que se utilizó en la selección de la muestra original, en este caso implica que para cada remuestra debes tomar muestra aleatoria independiente dentro de cada estrato.
    
Primero obtenemos una lista con todos los estratos de la muestra

```{r}
tabla_muestra <- muestra_tidy %>% 
#  mutate(si_no_nul = paste(SI,NO,NULOS)) %>% 
  select(ESTRATO, SI,NO, NULOS, TOTAL, n)

tabla_muestra

estratos <- unique(muestra_tidy$ESTRATO)

estratos[1]
EST <- dim(tibble(estratos))[1]
EST

tablaN <- tabla5 %>% select(ESTRATO, Nh)
tablaN

```

```{r}
Super_boot<- function(tabla_muestra, estratos, EST, tablaN){
N_boot <- 1000
boot_final <- tibble(p_SI = numeric(), p_NO = numeric(), p_NUL = numeric())
for (j in 1:N_boot) {
  muestra_boot = tibble()
  for (i in 1:EST) {
    est_temp <- tabla_muestra[which(tabla_muestra$ESTRATO == estratos[i]),]
#    n_chica = mean(est_temp$n)
    est_temp <- est_temp %>%  slice_sample(replace = TRUE, prop = 1)
#   sample_n(tabla_muestra, n_chica, replace=T)
    muestra_boot <- rbind(muestra_boot, est_temp)
  }
  m_boot = tibble()
  m_boot <- muestra_boot %>%
    group_by(ESTRATO) %>% 
    summarise(nh = mean(n), 
            yh_SI = sum(SI), 
            yh_NO = sum(NO), 
            yh_NUL = sum(NULOS),
            xh = sum(TOTAL))
  m_boot <- merge(x=m_boot,y=tablaN, by=c("ESTRATO"="ESTRATO"), all.x = TRUE)
  m_boot <-  m_boot %>% 
  mutate(p_SI_num =  Nh/nh*yh_SI,
         p_NO_num =  Nh/nh*yh_NO,
         p_NUL_num = Nh/nh*yh_NUL,
         p_denominador = Nh/nh*xh)%>% 
  summarise(p_SI = sum(p_SI_num)/sum(p_denominador),
            p_NO = sum(p_NO_num)/sum(p_denominador),
            p_NUL = sum(p_NUL_num)/sum(p_denominador))
  boot_final <-  boot_final %>% add_row(m_boot)
}
return(boot_final)
}
boot_final <-  Super_boot(tabla_muestra, estratos, EST, tablaN)
```

Una vez realizado el bootstrap, el error estándar es igual a la desviación estándar de la distribución bootstrap:


```{r}
error <- boot_final %>% 
  summarise(ee_si = sd(p_SI),
             ee_no = sd(p_NO),
             ee_nul = sd(p_NUL))
error

```

3.  Construye un intervalo del 95% de confianza utilizando el método normal. Revisa si el supuesto de normalidad es razonable.

**Los intervalos de confianza se construyen como (p_gorro-2ee,p_gorro+2ee)**

```{r}
intervalo <- boot_final %>% 
  summarize(si_int_inf = mean(p_SI)-2*sd(p_SI), si_int_sup = mean(p_SI)+2*sd(p_SI),
            no_int_inf = mean(p_NO)-2*sd(p_NO), no_int_sup = mean(p_NO)+2*sd(p_NO),
            nul_int_inf = mean(p_NUL)-2*sd(p_NUL), nul_int_sup = mean(p_NUL)+2*sd(p_NUL))
intervalo
```


**Para revisar el supuesto de normalidad hacemos la gráfica de cuantiles normales**

```{r}
g_hist1 <- ggplot(boot_final, aes(x = p_SI)) + geom_histogram(bins = 15)
g_hist2 <- ggplot(boot_final, aes(x = p_NO)) + geom_histogram(bins = 15)
g_hist3 <- ggplot(boot_final, aes(x = p_NUL)) + geom_histogram(bins = 15)

g_qq_normal1 <- ggplot(boot_final, aes(sample = p_SI)) +
  geom_qq() + geom_qq_line(colour = "red")
g_qq_normal2 <- ggplot(boot_final, aes(sample = p_NO)) +
  geom_qq() + geom_qq_line(colour = "red")
g_qq_normal3 <- ggplot(boot_final, aes(sample = p_NUL)) +
  geom_qq() + geom_qq_line(colour = "red")


g_hist1 + g_qq_normal1
g_hist2 + g_qq_normal2
g_hist3 + g_qq_normal3
```
**FALTA HABLAR DE LAS COLAS **

4.  Reporta tus intervalos en una tabla. Compara la longitud de los 3 intervalos y describe que observas.

**FALTA TABLA**

5.  ¿Tus intervalos contienen los valores observados en los cómputos? Explica los resultados observados.

**Los tres intervalos contienen a los p_gorro calculados**


#### Calibración

Selecciona al menos 50 muestras del mismo tamaño y con el mismo diseño que la muestra utilizada en el conteo rápido. Esto es, selecciona el mismo número de casillas, usando muestreo aleatorio simple dentro de cada estrato.

```{r}
tabla_calib <- computos %>% 
  select(OPINION_SI, OPINION_NO, NULOS, ESTRATO, TOTAL_OPINIONES)%>% 
        rename("SI" = "OPINION_SI",
               "NO" = "OPINION_NO",
               "TOTAL" = "TOTAL_OPINIONES")
tabla_temporal <-  tabla_muestra %>% select(ESTRATO,n)
tabla_calib <- merge(x=tabla_calib,y=tabla_temporal, by=c("ESTRATO"="ESTRATO"), all.x = TRUE)
tabla_calib
tabla_muestra
```


```{r}
#df3 <- cbind(df, chapters, price)
muestras_calibracion = tibble()
for (j in 1:50) {
  muestra_intervalos = tibble()
  id <- rep(j,1745)
  for (i in 1:EST) {
    est_temp <- tabla_calib[which(tabla_calib$ESTRATO == estratos[i]),]
    n_chica = mean(est_temp$n)
    est_temp <- est_temp %>%  slice_sample(n = n_chica)
#   sample_n(tabla_muestra, n_chica, replace=T)
    muestra_intervalos <- rbind(muestra_intervalos, est_temp)
  }
  muestra_intervalos <- cbind(id,muestra_intervalos)
  muestras_calibracion <- rbind(muestras_calibracion, muestra_intervalos)
}
  
```


-   Para cada muestra calcula un intervalo del 95% de confianza usando bootstrap.

```{r}
tabla_aux <- muestras_calibracion[which(muestras_calibracion$id == 5),]

tabla_aux %>% select(ESTRATO, SI, NO, NULOS, TOTAL,n)

boot_aux <- Super_boot(tabla_aux, estratos, EST, tablaN)
boot_aux


```


-   Grafica los intervalos y calcula la proporción de ellos que contienen el verdadero valor observado. Describe tus observaciones y compara con el intervalo obtenido en el ejercicio anterior.



#### Análisis Exploratorio

Un voto nulo corresponde a una boleta donde el ciudadano acudió a las urnas y anuló su voto.

Antes de contestar los siguiente incisos piensen que rango esperarían ver para la proporción de votos nulos en una casilla.

-   Describe la distribución de datos nulos en la muestra, y como se relaciona con el total de votos, realiza gráficas y describe tus observaciones.

```{r}
nul_tabla <- muestra_tidy %>% select(NULOS, TOTAL)

nul1 <- ggplot(nul_tabla, aes(x = NULOS)) + geom_histogram(bins = 15, fill = "red")

nul_tabla2 <- nul_tabla %>% 
  filter(NULOS > 500)

nul2 <- ggplot(nul_tabla2, aes(x = NULOS)) + geom_histogram(bins = 15, fill = "red")

nul1+nul2

```


-   En la distribución de proporción de nulos se observan datos atípicos, ¿cuál crees que sea la razón de estas observaciones extremas? ¿consideras que se deben eliminar de la muestra antes de realizar la estimación?




